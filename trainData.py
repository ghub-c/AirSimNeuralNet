# -*- coding: utf-8 -*-
import numpy as np
import tensorflow as tf
from skimage import color
from skimage import io


#Image directory inside the project
IMAGEDIR = './dataset'

#File to store weights and biases
PARAMFILE = 'model.pkl'

#Number of images collected in the getData script
maximages = 10
#Images near to the collision
crashimages= 1
#Parameters
#How quickly the network abandons old beliefs for new ones
learning_rate = 0.01
#Number of times the system goes through all the training samples
training_epochs = 500
#Number of samples propagated through the network
batch_size = 100
#To display logs per epoch step
display_step = 10

def inference(x, xsize, ysize, W_vals=0, b_vals=0):
    
    '''
    Softmax inference layer implementation (Logistic regression)
    Obtained from Fundamentals of Deep Learning Book
    '''
    
    W_init = tf.constant_initializer(value=W_vals)
    b_init = tf.constant_initializer(value=b_vals)
    W = tf.get_variable('W', [xsize, ysize], initializer=W_init)
    b = tf.get_variable('b', [ysize],        initializer=b_init)
    output = tf.nn.softmax(tf.matmul(x, W) + b)

    return output

def loss(output, y):
    dot_product = y * tf.log(output)

    #Reduction along axis 0 collapses each column into a single
    #value, whereas reduction along axis 1 collapses each row 
    #into a single value. In general, reduction along axis i 
    #collapses the ith dimension of a tensor to size 1.
    xentropy = -tf.reduce_sum(dot_product, axis=1)
     
    loss = tf.reduce_mean(xentropy)

    return loss

def main():
    
    #Number of pixels in each image
    imgpixels = 0
    
    images = []
    for k in range(maximages):
        
       #Convert images generated by the getData script to greyscale and flatten
       #Uses luminosity method 0.21R + 0.72G + 0.07B. Then flattens to a single layer
       
        image = color.rgb2gray(io.imread(IMAGEDIR + '/image%03d.png' % k))
        image = image.flatten()
        imgpixels = np.prod(image.shape)
        
    #Separate image (01 are no-crash image, and 10 are crash images)    
    targets = []
    for k in range(maximages-crashimages):
        targets.append([0,1])
    targets.append([1,0])
    
    #Tensorflow
    with tf.Graph().as_default():
        
        x = tf.placeholder('float', [None, imgpixels])
        y = tf.placeholder('float', [None, 2])
        
        output = inference(x, imgpixels, 2)
        print ('Output is:', output)
        cost = loss(output, y)
        print ('Cost is:', cost)
        
#This executes main method automatically when we run the script
if __name__ == '__main__':
    
    main()